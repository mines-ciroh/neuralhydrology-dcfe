{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebe331b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "from neuralhydrology.utils.config import Config\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from neuralhydrology.evaluation import metrics\n",
    "from neuralhydrology.nh_run import start_run, eval_run\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53eb0740",
   "metadata": {},
   "source": [
    "# MISC Function Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4125ce2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralhydrology.modelzoo.cfe_modules.dcfe_utils import get_dcfe_params\n",
    "from neuralhydrology.datautils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f37fcf71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "depth                                                        tensor(2.)\n",
       "bb                                                       tensor(1.8747)\n",
       "satdk                                                    tensor(0.0007)\n",
       "satpsi                                                   tensor(0.1889)\n",
       "slop                                                     tensor(0.8340)\n",
       "smcmax                                                   tensor(0.2987)\n",
       "wltsmc                                                   tensor(0.0521)\n",
       "D                                                            tensor(2.)\n",
       "mult                                                         tensor(1.)\n",
       "catchment_area_km2                                     tensor(111.1100)\n",
       "refkdt                                                   tensor(0.8883)\n",
       "max_gw_storage                                           tensor(0.2016)\n",
       "expon                                                    tensor(1.8009)\n",
       "Cgw                                                      tensor(0.0003)\n",
       "alpha_fc                                                 tensor(0.3300)\n",
       "K_nash                                                   tensor(0.0980)\n",
       "K_lf                                                     tensor(0.8121)\n",
       "nash_storage                                   [tensor(0.), tensor(0.)]\n",
       "giuh_ordinates        [tensor(0.3300), tensor(0.2900), tensor(0.1900...\n",
       "Name: 02177000, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_path = Path('/Users/ziyu/Library/CloudStorage/OneDrive-ColoradoSchoolofMines/Documents/College/ResearchStuff/NextGen/neuralhydrology-dcfe/examples/07-DCFE/2basinTest_dynamic.yml')\n",
    "config = Config(config_path, dev_mode=True)\n",
    "basins = utils.load_basin_file(getattr(config, \"train_basin_file\"))\n",
    "\n",
    "testDF = get_dcfe_params(config)\n",
    "testDF.loc['02177000']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e03ba7",
   "metadata": {},
   "source": [
    "We expect the above to return \n",
    "depth                                                        tensor(2.)\n",
    "bb                                                       tensor(1.8747)\n",
    "satdk                                                    tensor(0.0007)\n",
    "satpsi                                                   tensor(0.1889)\n",
    "slop                                                     tensor(0.8340)\n",
    "smcmax                                                   tensor(0.2987)\n",
    "wltsmc                                                   tensor(0.0521)\n",
    "D                                                            tensor(2.)\n",
    "mult                                                         tensor(1.)\n",
    "catchment_area_km2                                     tensor(111.1100)\n",
    "refkdt                                                   tensor(0.8883)\n",
    "max_gw_storage                                           tensor(0.2016)\n",
    "expon                                                    tensor(1.8009)\n",
    "Cgw                                                      tensor(0.0003)\n",
    "alpha_fc                                                 tensor(0.3300)\n",
    "K_nash                                                   tensor(0.0980)\n",
    "K_lf                                                     tensor(0.8121)\n",
    "nash_storage                                   [tensor(0.), tensor(0.)]\n",
    "giuh_ordinates        [tensor(0.3300), tensor(0.2900), tensor(0.1900...\n",
    "Name: 02177000, dtype: object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6805cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8b09151",
   "metadata": {},
   "source": [
    "# Dynamic Daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8f33279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-01 13:28:03,102: Logging to /Users/ziyu/Library/CloudStorage/OneDrive-ColoradoSchoolofMines/Documents/College/ResearchStuff/NextGen/neuralhydrology-dcfe/examples/07-DCFE/runs/DevMultiBasin_Test_0112_132803/output.log initialized.\n",
      "2025-12-01 13:28:03,102: ### Folder structure created at /Users/ziyu/Library/CloudStorage/OneDrive-ColoradoSchoolofMines/Documents/College/ResearchStuff/NextGen/neuralhydrology-dcfe/examples/07-DCFE/runs/DevMultiBasin_Test_0112_132803\n",
      "2025-12-01 13:28:03,103: ### Run configurations for DevMultiBasin_Test\n",
      "2025-12-01 13:28:03,103: experiment_name: DevMultiBasin_Test\n",
      "2025-12-01 13:28:03,103: train_basin_file: 2_basin.txt\n",
      "2025-12-01 13:28:03,104: validation_basin_file: 2_basin.txt\n",
      "2025-12-01 13:28:03,104: test_basin_file: 2_basin.txt\n",
      "2025-12-01 13:28:03,105: train_start_date: 2000-10-01 00:00:00\n",
      "2025-12-01 13:28:03,105: train_end_date: 2014-09-30 00:00:00\n",
      "2025-12-01 13:28:03,106: validation_start_date: 1990-10-01 00:00:00\n",
      "2025-12-01 13:28:03,106: validation_end_date: 1999-09-30 00:00:00\n",
      "2025-12-01 13:28:03,106: test_start_date: 1999-10-01 00:00:00\n",
      "2025-12-01 13:28:03,106: test_end_date: 2000-09-30 00:00:00\n",
      "2025-12-01 13:28:03,107: device: cpu\n",
      "2025-12-01 13:28:03,107: validate_every: 2\n",
      "2025-12-01 13:28:03,108: validate_n_random_basins: 1\n",
      "2025-12-01 13:28:03,109: metrics: ['NSE']\n",
      "2025-12-01 13:28:03,109: model: hybrid_model\n",
      "2025-12-01 13:28:03,109: conceptual_model: dcfe\n",
      "2025-12-01 13:28:03,110: dcfe_soil_scheme: classic\n",
      "2025-12-01 13:28:03,110: dcfe_partition_scheme: Schaake\n",
      "2025-12-01 13:28:03,111: dcfe_hourly: False\n",
      "2025-12-01 13:28:03,111: conceptual_param_config: dynamic\n",
      "2025-12-01 13:28:03,112: head: regression\n",
      "2025-12-01 13:28:03,112: output_activation: linear\n",
      "2025-12-01 13:28:03,112: hidden_size: 20\n",
      "2025-12-01 13:28:03,113: initial_forget_bias: 3\n",
      "2025-12-01 13:28:03,113: output_dropout: 0.2\n",
      "2025-12-01 13:28:03,113: optimizer: Adam\n",
      "2025-12-01 13:28:03,114: loss: MSE\n",
      "2025-12-01 13:28:03,114: learning_rate: {0: 0.05, 20: 0.001, 40: 1e-05}\n",
      "2025-12-01 13:28:03,114: batch_size: 256\n",
      "2025-12-01 13:28:03,114: epochs: 3\n",
      "2025-12-01 13:28:03,115: clip_gradient_norm: 1\n",
      "2025-12-01 13:28:03,115: predict_last_n: 365\n",
      "2025-12-01 13:28:03,116: seq_length: 910\n",
      "2025-12-01 13:28:03,116: warmup_period: 180\n",
      "2025-12-01 13:28:03,117: spin_up_period: 365\n",
      "2025-12-01 13:28:03,118: num_workers: 8\n",
      "2025-12-01 13:28:03,118: log_interval: 5\n",
      "2025-12-01 13:28:03,119: log_tensorboard: True\n",
      "2025-12-01 13:28:03,119: log_n_figures: 1\n",
      "2025-12-01 13:28:03,120: save_weights_every: 1\n",
      "2025-12-01 13:28:03,120: seed: 123\n",
      "2025-12-01 13:28:03,120: dataset: camels_us\n",
      "2025-12-01 13:28:03,120: data_dir: /Users/ziyu/Library/CloudStorage/OneDrive-ColoradoSchoolofMines/Documents/College/ResearchStuff/NextGen/Code/data/CAMELS_US\n",
      "2025-12-01 13:28:03,121: conceptual_dir: /Users/ziyu/Library/CloudStorage/OneDrive-ColoradoSchoolofMines/Documents/College/ResearchStuff/NextGen/Code/data/Conceptual\n",
      "2025-12-01 13:28:03,121: forcings: ['maurer', 'daymet', 'nldas']\n",
      "2025-12-01 13:28:03,122: dynamic_inputs: ['PRCP(mm/day)_nldas', 'PRCP(mm/day)_maurer', 'prcp(mm/day)_daymet', 'srad(W/m2)_daymet', 'tmax(C)_daymet', 'tmin(C)_daymet', 'vp(Pa)_daymet']\n",
      "2025-12-01 13:28:03,122: duplicate_features: ['PRCP(mm/day)_nldas', 'tmax(C)_daymet', 'tmin(C)_daymet', 'srad(W/m2)_daymet']\n",
      "2025-12-01 13:28:03,122: dynamic_conceptual_inputs: ['PRCP(mm/day)_nldas_copy1', 'tmin(C)_daymet_copy1', 'tmax(C)_daymet_copy1', 'srad(W/m2)_daymet_copy1']\n",
      "2025-12-01 13:28:03,123: custom_normalization: {'QObs(mm/d)': {'centering': 'None', 'scaling': 'None'}, 'PRCP(mm/day)_nldas_copy1': {'centering': 'None', 'scaling': 'None'}, 'srad(W/m2)_daymet_copy1': {'centering': 'None', 'scaling': 'None'}, 'tmin(C)_daymet_copy1': {'centering': 'None', 'scaling': 'None'}, 'tmax(C)_daymet_copy1': {'centering': 'None', 'scaling': 'None'}}\n",
      "2025-12-01 13:28:03,123: target_variables: ['QObs(mm/d)']\n",
      "2025-12-01 13:28:03,124: clip_targets_to_zero: ['QObs(mm/d)']\n",
      "2025-12-01 13:28:03,124: number_of_basins: 2\n",
      "2025-12-01 13:28:03,125: run_dir: /Users/ziyu/Library/CloudStorage/OneDrive-ColoradoSchoolofMines/Documents/College/ResearchStuff/NextGen/neuralhydrology-dcfe/examples/07-DCFE/runs/DevMultiBasin_Test_0112_132803\n",
      "2025-12-01 13:28:03,126: train_dir: /Users/ziyu/Library/CloudStorage/OneDrive-ColoradoSchoolofMines/Documents/College/ResearchStuff/NextGen/neuralhydrology-dcfe/examples/07-DCFE/runs/DevMultiBasin_Test_0112_132803/train_data\n",
      "2025-12-01 13:28:03,126: img_log_dir: /Users/ziyu/Library/CloudStorage/OneDrive-ColoradoSchoolofMines/Documents/College/ResearchStuff/NextGen/neuralhydrology-dcfe/examples/07-DCFE/runs/DevMultiBasin_Test_0112_132803/img_log\n",
      "2025-12-01 13:28:03,179: ### Device cpu will be used for training\n",
      "2025-12-01 13:28:03,180: Loading basin data into xarray data set.\n",
      "100%|██████████| 2/2 [00:00<00:00,  8.63it/s]\n",
      "2025-12-01 13:28:03,465: Create lookup table and convert to pytorch tensor\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67it/s]\n",
      "# Epoch 1:   0%|          | 0/21 [00:12<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'static_conceptual_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstart_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2basinTest_dynamic.yml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ColoradoSchoolofMines/Documents/College/ResearchStuff/NextGen/neuralhydrology-dcfe/neuralhydrology/nh_run.py:77\u001b[0m, in \u001b[0;36mstart_run\u001b[0;34m(config_file, gpu)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gpu \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gpu \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     75\u001b[0m     config\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 77\u001b[0m \u001b[43mstart_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ColoradoSchoolofMines/Documents/College/ResearchStuff/NextGen/neuralhydrology-dcfe/neuralhydrology/training/train.py:20\u001b[0m, in \u001b[0;36mstart_training\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown head \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg\u001b[38;5;241m.\u001b[39mhead\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m trainer\u001b[38;5;241m.\u001b[39minitialize_training()\n\u001b[0;32m---> 20\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_and_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ColoradoSchoolofMines/Documents/College/ResearchStuff/NextGen/neuralhydrology-dcfe/neuralhydrology/training/basetrainer.py:232\u001b[0m, in \u001b[0;36mBaseTrainer.train_and_validate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m    230\u001b[0m             param_group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mlearning_rate[epoch]\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m avg_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment_logger\u001b[38;5;241m.\u001b[39msummarise()\n\u001b[1;32m    234\u001b[0m loss_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m avg_losses\u001b[38;5;241m.\u001b[39mitems())\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ColoradoSchoolofMines/Documents/College/ResearchStuff/NextGen/neuralhydrology-dcfe/neuralhydrology/training/basetrainer.py:323\u001b[0m, in \u001b[0;36mBaseTrainer._train_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    320\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpre_model_hook(data, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    322\u001b[0m \u001b[38;5;66;03m# get predictions\u001b[39;00m\n\u001b[0;32m--> 323\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise_sampler_y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m k: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m k, data\u001b[38;5;241m.\u001b[39mkeys()):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ColoradoSchoolofMines/Documents/College/ResearchStuff/NextGen/neuralhydrology-dcfe/neuralhydrology/modelzoo/hybridmodel.py:75\u001b[0m, in \u001b[0;36mHybridModel.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# get predictions\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mconceptual_model\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdcfe\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# dCFE only\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconceptual_model(\n\u001b[1;32m     73\u001b[0m         x_conceptual\u001b[38;5;241m=\u001b[39mx_conceptual,\n\u001b[1;32m     74\u001b[0m         lstm_out\u001b[38;5;241m=\u001b[39mlstm_out,\n\u001b[0;32m---> 75\u001b[0m         additional_features\u001b[38;5;241m=\u001b[39m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstatic_conceptual_params\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[1;32m     76\u001b[0m     )\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconceptual_model(\n\u001b[1;32m     79\u001b[0m         x_conceptual\u001b[38;5;241m=\u001b[39mx_conceptual,\n\u001b[1;32m     80\u001b[0m         lstm_out\u001b[38;5;241m=\u001b[39mlstm_out,\n\u001b[1;32m     81\u001b[0m     )\n",
      "\u001b[0;31mKeyError\u001b[0m: 'static_conceptual_params'"
     ]
    }
   ],
   "source": [
    "start_run(config_file=Path(\"2basinTest_dynamic.yml\"), gpu=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
