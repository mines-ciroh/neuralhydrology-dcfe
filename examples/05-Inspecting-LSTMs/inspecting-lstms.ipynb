{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# CustomLSTM: Inspecting LSTM States and Activations\n",
    "\n",
    "**Before we start**\n",
    "\n",
    "- This tutorial is rendered from a Jupyter notebook that is hosted on GitHub. If you want to run the code yourself, you can find the notebook and configuration files [here](https://github.com/neuralhydrology/neuralhydrology/tree/master/examples/05-Inspecting-LSTMs).\n",
    "- To be able to run this notebook locally, you need to download the publicly available CAMELS US rainfall-runoff dataset. See the [Data Prerequisites Tutorial](data-prerequisites.nblink) for a detailed description on where to download the data and how to structure your local dataset folder.\n",
    "\n",
    "This tutorial shows how to use `CustomLSTM` to inspect the states and activations of a trained LSTM.\n",
    "In previous publications, we have seen that the internals of LSTM seem to resemble physically meaningful quantities. For instance, [this publication](https://link.springer.com/chapter/10.1007/978-3-030-28954-6_19) found cells that are highly correlated to snow water equivalent (SWE), even though the LSTM had never seen SWE data during training.\n",
    "While `CudaLSTM` is great for fast training of models, it limits the insights we can draw from model internals such as states and activations.\n",
    "This is where `CustomLSTM` comes into play: `CustomLSTM` is another LSTM implementation that is much slower but that can return much more information on cell/hidden states and activations.\n",
    "\n",
    "To train an LSTM model, you'll always want to use `CudaLSTM` since it makes use of PyTorch's pre-implemented LSTM with all its optimizations. Therefore, it's way faster than anything we could build ourselves.\n",
    "Since `CustomLSTM` is slower than `CudaLSTM`, the usual workflow is: \n",
    "\n",
    "1. train a `CudaLSTM`\n",
    "2. copy the `CudaLSTM` weights into a `CustomLSTM`\n",
    "3. analyze the states/activations in the `CustomLSTM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from neuralhydrology.datasetzoo import get_dataset, camelsus\n",
    "from neuralhydrology.datautils.utils import load_scaler\n",
    "from neuralhydrology.modelzoo.cudalstm import CudaLSTM\n",
    "from neuralhydrology.modelzoo.customlstm import CustomLSTM\n",
    "from neuralhydrology.nh_run import start_run\n",
    "from neuralhydrology.utils.config import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, let's train a \"normal\" LSTM (i.e., a `CudaLSTM`), just like we did in the introduction tutorial. (Again, for quick results, we train the model on a single basin. If you actually care about good predictions, don't do this. Train one model on lots of basins combined.). \n",
    "\n",
    "\n",
    "**Note**\n",
    "\n",
    "- The config file assumes that the CAMELS US dataset is stored under `data/CAMELS_US` (relative to the main directory of this repository) or a symbolic link exists at this location. Make sure that this folder contains the required subdirectories `basin_mean_forcing`, `usgs_streamflow` and `camels_attributes_v2.0`. If your data is stored at a different location and you can't or don't want to create a symbolic link, you will need to change the `data_dir` argument in the `1_basin.yml` config file that is located in the same directory as this notebook.\n",
    "- By default, the config (`1_basin.yml`) assumes that you have a CUDA-capable NVIDIA GPU (see config argument `device`). In case you don't have any or you have one but want to train on the CPU, you can either change the config argument to `device: cpu` or pass `gpu=-1` to the `start_run()` function.\n",
    "- If you want to train on MacOS devices with Metal programming framework which enables high-performance training on GPU for MacOS, change the config argument to `device: mps` and don't pass the `gpu` argument to the `start_run()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-05 12:42:44,265: Logging to /Users/danielmckenzie/Documents/Active_Research/Ziyu/neuralhydrology-dcfe/examples/05-Inspecting-LSTMs/runs/test_run_0512_124244/output.log initialized.\n",
      "2025-12-05 12:42:44,265: ### Folder structure created at /Users/danielmckenzie/Documents/Active_Research/Ziyu/neuralhydrology-dcfe/examples/05-Inspecting-LSTMs/runs/test_run_0512_124244\n",
      "2025-12-05 12:42:44,265: ### Run configurations for test_run\n",
      "2025-12-05 12:42:44,266: experiment_name: test_run\n",
      "2025-12-05 12:42:44,266: train_basin_file: 1_basin.txt\n",
      "2025-12-05 12:42:44,267: validation_basin_file: 1_basin.txt\n",
      "2025-12-05 12:42:44,267: test_basin_file: 1_basin.txt\n",
      "2025-12-05 12:42:44,267: train_start_date: 1999-10-01 00:00:00\n",
      "2025-12-05 12:42:44,268: train_end_date: 2008-09-30 00:00:00\n",
      "2025-12-05 12:42:44,268: validation_start_date: 1980-10-01 00:00:00\n",
      "2025-12-05 12:42:44,268: validation_end_date: 1989-09-30 00:00:00\n",
      "2025-12-05 12:42:44,269: test_start_date: 1989-10-01 00:00:00\n",
      "2025-12-05 12:42:44,269: test_end_date: 1999-09-30 00:00:00\n",
      "2025-12-05 12:42:44,269: device: mps\n",
      "2025-12-05 12:42:44,269: validate_every: 5\n",
      "2025-12-05 12:42:44,270: validate_n_random_basins: 1\n",
      "2025-12-05 12:42:44,270: metrics: ['NSE']\n",
      "2025-12-05 12:42:44,270: model: cudalstm\n",
      "2025-12-05 12:42:44,270: head: regression\n",
      "2025-12-05 12:42:44,270: output_activation: linear\n",
      "2025-12-05 12:42:44,271: hidden_size: 20\n",
      "2025-12-05 12:42:44,271: initial_forget_bias: 3\n",
      "2025-12-05 12:42:44,271: output_dropout: 0.4\n",
      "2025-12-05 12:42:44,271: optimizer: Adam\n",
      "2025-12-05 12:42:44,271: loss: MSE\n",
      "2025-12-05 12:42:44,272: learning_rate: {0: 0.01, 15: 0.005}\n",
      "2025-12-05 12:42:44,272: batch_size: 256\n",
      "2025-12-05 12:42:44,272: epochs: 30\n",
      "2025-12-05 12:42:44,272: clip_gradient_norm: 1\n",
      "2025-12-05 12:42:44,272: predict_last_n: 1\n",
      "2025-12-05 12:42:44,272: seq_length: 365\n",
      "2025-12-05 12:42:44,273: num_workers: 8\n",
      "2025-12-05 12:42:44,273: log_interval: 5\n",
      "2025-12-05 12:42:44,273: log_tensorboard: True\n",
      "2025-12-05 12:42:44,273: log_n_figures: 1\n",
      "2025-12-05 12:42:44,273: save_weights_every: 1\n",
      "2025-12-05 12:42:44,274: dataset: camels_us\n",
      "2025-12-05 12:42:44,274: data_dir: ../../data/CAMELS_US\n",
      "2025-12-05 12:42:44,274: forcings: daymet\n",
      "2025-12-05 12:42:44,275: dynamic_inputs: ['prcp(mm/day)', 'srad(W/m2)', 'tmax(C)', 'tmin(C)', 'vp(Pa)']\n",
      "2025-12-05 12:42:44,275: target_variables: ['QObs(mm/d)']\n",
      "2025-12-05 12:42:44,275: clip_targets_to_zero: ['QObs(mm/d)']\n",
      "2025-12-05 12:42:44,276: number_of_basins: 1\n",
      "2025-12-05 12:42:44,276: run_dir: /Users/danielmckenzie/Documents/Active_Research/Ziyu/neuralhydrology-dcfe/examples/05-Inspecting-LSTMs/runs/test_run_0512_124244\n",
      "2025-12-05 12:42:44,276: train_dir: /Users/danielmckenzie/Documents/Active_Research/Ziyu/neuralhydrology-dcfe/examples/05-Inspecting-LSTMs/runs/test_run_0512_124244/train_data\n",
      "2025-12-05 12:42:44,276: img_log_dir: /Users/danielmckenzie/Documents/Active_Research/Ziyu/neuralhydrology-dcfe/examples/05-Inspecting-LSTMs/runs/test_run_0512_124244/img_log\n",
      "2025-12-05 12:42:44,279: ### Device mps will be used for training\n",
      "2025-12-05 12:42:44,280: Loading basin data into xarray data set.\n",
      "100%|██████████| 1/1 [00:00<00:00, 23.30it/s]\n",
      "2025-12-05 12:42:44,339: Create lookup table and convert to pytorch tensor\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.79it/s]\n",
      "# Epoch 1:   0%|          | 0/13 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/danielmckenzie/Documents/Active_Research/Ziyu/neuralhydrology-dcfe/.venv/lib/python3.13/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/Users/danielmckenzie/Documents/Active_Research/Ziyu/neuralhydrology-dcfe/.venv/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/Users/danielmckenzie/Documents/Active_Research/Ziyu/neuralhydrology-dcfe/neuralhydrology/datasetzoo/basedataset.py\", line 199, in __getitem__\n    sample[\"static_conceptual_params\"] = self.static_conceptual_params.loc[basin]\n                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'CamelsUS' object has no attribute 'static_conceptual_params'. Did you mean: '_load_conceptual_params'?\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# by default we assume that you have at least one CUDA-capable NVIDIA GPU or MacOS with Metal support\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mmps\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mstart_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# fall back to CPU-only mode\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      8\u001b[0m     start_run(config_file\u001b[38;5;241m=\u001b[39mconfig_file, gpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Active_Research/Ziyu/neuralhydrology-dcfe/neuralhydrology/nh_run.py:77\u001b[0m, in \u001b[0;36mstart_run\u001b[0;34m(config_file, gpu)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gpu \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gpu \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     75\u001b[0m     config\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 77\u001b[0m \u001b[43mstart_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Active_Research/Ziyu/neuralhydrology-dcfe/neuralhydrology/training/train.py:20\u001b[0m, in \u001b[0;36mstart_training\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown head \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg\u001b[38;5;241m.\u001b[39mhead\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m trainer\u001b[38;5;241m.\u001b[39minitialize_training()\n\u001b[0;32m---> 20\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_and_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Active_Research/Ziyu/neuralhydrology-dcfe/neuralhydrology/training/basetrainer.py:233\u001b[0m, in \u001b[0;36mBaseTrainer.train_and_validate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m    231\u001b[0m             param_group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mlearning_rate[epoch]\n\u001b[0;32m--> 233\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m avg_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment_logger\u001b[38;5;241m.\u001b[39msummarise()\n\u001b[1;32m    235\u001b[0m loss_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m avg_losses\u001b[38;5;241m.\u001b[39mitems())\n",
      "File \u001b[0;32m~/Documents/Active_Research/Ziyu/neuralhydrology-dcfe/neuralhydrology/training/basetrainer.py:310\u001b[0m, in \u001b[0;36mBaseTrainer._train_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;66;03m# Iterate in batches over training set\u001b[39;00m\n\u001b[1;32m    309\u001b[0m nan_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 310\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_updates_per_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_updates_per_epoch\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mbreak\u001b[39;49;00m\n",
      "File \u001b[0;32m~/Documents/Active_Research/Ziyu/neuralhydrology-dcfe/.venv/lib/python3.13/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/Documents/Active_Research/Ziyu/neuralhydrology-dcfe/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m~/Documents/Active_Research/Ziyu/neuralhydrology-dcfe/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:1480\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[1;32m   1479\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rcvd_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1480\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Active_Research/Ziyu/neuralhydrology-dcfe/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:1505\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1505\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/Documents/Active_Research/Ziyu/neuralhydrology-dcfe/.venv/lib/python3.13/site-packages/torch/_utils.py:733\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mAttributeError\u001b[0m: Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/danielmckenzie/Documents/Active_Research/Ziyu/neuralhydrology-dcfe/.venv/lib/python3.13/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/Users/danielmckenzie/Documents/Active_Research/Ziyu/neuralhydrology-dcfe/.venv/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/Users/danielmckenzie/Documents/Active_Research/Ziyu/neuralhydrology-dcfe/neuralhydrology/datasetzoo/basedataset.py\", line 199, in __getitem__\n    sample[\"static_conceptual_params\"] = self.static_conceptual_params.loc[basin]\n                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'CamelsUS' object has no attribute 'static_conceptual_params'. Did you mean: '_load_conceptual_params'?\n"
     ]
    }
   ],
   "source": [
    "config_file = Path(\"1_basin.yml\")\n",
    "# by default we assume that you have at least one CUDA-capable NVIDIA GPU or MacOS with Metal support\n",
    "if torch.cuda.is_available() or torch.backends.mps.is_available():\n",
    "    start_run(config_file=config_file)\n",
    "\n",
    "# fall back to CPU-only mode\n",
    "else:\n",
    "    start_run(config_file=config_file, gpu=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the config we used for training has `save_weights_every` set to 1, we now have the weights of the model for every epoch in the run directory. Since the name of the run directory is created dynamically (including the date and time of the start of the run) you will need to change the `run_dir` argument according to your local directory name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir = Path('runs/test_run_0501_221039')  # this value comes from the output of the above command\n",
    "!ls $run_dir/model_epoch* | tail -n 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll go ahead and load the final model (from epoch 30), so we can inspect its states and activations in more detail.\n",
    "To do so, we first have to create a new CudaLSTM instance that we can then populate with the saved weights.\n",
    "\n",
    "Small gotcha along the way: Make sure to set `map_location` to the device that you want to use for the loaded model. E.g., if you trained the above model on a GPU but want to do the subsequent weights analysis on CPU, you need to set `map_location='cpu'` so that the weights are loaded properly. Without this argument, you'll run into errors if you load a GPU model on a CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudalstm_config = Config(config_file)\n",
    "\n",
    "# create a new model instance with random weights\n",
    "cuda_lstm = CudaLSTM(cfg=cudalstm_config)\n",
    "\n",
    "# load the trained weights into the new model. \n",
    "model_path = run_dir / 'model_epoch030.pt'\n",
    "model_weights = torch.load(str(model_path), map_location='cpu')  # load the weights from the file, creating the weight tensors on CPU\n",
    "cuda_lstm.load_state_dict(model_weights)  # set the new model's weights to the values loaded from file\n",
    "cuda_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the same config to create our `CustomLSTM` and then use the method `.copy_weights()` to copy the weights of the trained `CudaLSTM` into the `CustomLSTM`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_lstm = CustomLSTM(cfg=cudalstm_config)  # create a new CustomLSTM (with random weights)\n",
    "custom_lstm.copy_weights(cuda_lstm)  # copy the CudaLSTM weights into the CustomLSTM\n",
    "custom_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have two models: The `CudaLSTM` that we trained in the beginning, and a `CustomLSTM` that has the exact same weights.\n",
    "Just to check, let's compare some of the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.allclose(cuda_lstm.lstm.bias_ih_l0, custom_lstm.cell.b_ih)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we're in eval mode where dropout is deactivated\n",
    "custom_lstm.eval()\n",
    "cuda_lstm.eval()\n",
    "\n",
    "# load the dataset\n",
    "scaler = load_scaler(run_dir)\n",
    "dataset = get_dataset(cudalstm_config, is_train=False, period='test', scaler=scaler)\n",
    "dataloader = DataLoader(dataset, batch_size=1000, shuffle=False, collate_fn=dataset.collate_fn)\n",
    "\n",
    "cudalstm_output = []\n",
    "customlstm_output = []\n",
    "# no need to calculate any gradients since we're just running some evaluations\n",
    "with torch.no_grad():\n",
    "    for sample in dataloader:\n",
    "        customlstm_output.append(custom_lstm(sample))\n",
    "        cudalstm_output.append(cuda_lstm(sample))\n",
    "\n",
    "print('CudaLSTM output:  ', list(cudalstm_output[0].keys()))\n",
    "print('CustomLSTM output:', list(customlstm_output[0].keys()))\n",
    "\n",
    "# check if predictions of CustomLSTM and CudaLSTM are identical\n",
    "print('Identical predictions:', torch.allclose(customlstm_output[0]['y_hat'], cudalstm_output[0]['y_hat'], atol=1e-5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the predictions of `CudaLSTM` and `CustomLSTM` are identical (up to a small tolerance). This makes sense, since we already know the models have the same weights.\n",
    "\n",
    "But we can also see that the `CustomLSTM` returns more than just the predictions in `y_hat`! There's also:\n",
    "\n",
    "| key | value |\n",
    "|:----|:-------|\n",
    "| `y_hat` | prediction |\n",
    "| `c_n` | cell state |\n",
    "| `h_n` | hidden state |\n",
    "| `i` | input gate activation |\n",
    "| `g` | cell input activation |\n",
    "| `f` | forget gate activation |\n",
    "| `o` | output gate activation |\n",
    "\n",
    "`CudaLSTM` has an additional `lstm_output` key, but that is identical to the sequence of hidden states `h_n`.\n",
    "\n",
    "While `CudaLSTM` retuns `c_n` and `h_n`, too, its tensors only contain the state at the last time step of each sample. `CustomLSTM` on the other hand returns the states for the full input sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CudaLSTM shape:  ', cudalstm_output[0]['c_n'].shape)  # [batch size, 1, hidden size]\n",
    "print('CustomLSTM shape:', customlstm_output[0]['c_n'].shape)  # [batch size, sequence length, hidden size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a closer look at the LSTM states and activations, look at how they evolve over time, and how this evolution correlates with input variables.\n",
    "For instance, cell state 7 quite closely follows the time series of temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all batches into one tensor that contains the final time step of each sample.\n",
    "cell_states = torch.cat([out['c_n'][:, -1, :] for out in customlstm_output], dim=0)\n",
    "\n",
    "# Load the forcings input for the corresponding date range\n",
    "date_range = pd.date_range(cudalstm_config.test_start_date, cudalstm_config.test_end_date, freq='1D')\n",
    "forcings = camelsus.load_camels_us_forcings(cudalstm_config.data_dir, '01022500', 'daymet')[0].loc[date_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, ax2) = plt.subplots(2, 1, figsize=(15, 6), sharex=True)\n",
    "\n",
    "ax.plot(date_range, cell_states, c='C0', alpha=.2)\n",
    "ax.plot(date_range, cell_states[:, 7], c='C0')\n",
    "\n",
    "ax.set_ylabel('cell state')\n",
    "ax2.set_ylabel('min/max temperature')\n",
    "\n",
    "ax2.plot(date_range, forcings['tmin(C)'], c='C1')\n",
    "ax2.plot(date_range, forcings['tmax(C)'], c='C2')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's look at how the cell and hidden states and the gate activations develop while the LSTM processes the input sequence of a single sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(4, 2, figsize=(20, 14), sharex=True)\n",
    "ax[0,0].set_title('Input values')\n",
    "lines = ax[0,0].plot(dataset[0]['x_d'])  # these are the normalized inputs we fed the LSTM above\n",
    "ax[0,0].legend(lines, cudalstm_config.dynamic_inputs, frameon=False)\n",
    "\n",
    "ax[1,0].set_title('Cell state')\n",
    "ax[1,0].plot(customlstm_output[0]['c_n'][0])\n",
    "\n",
    "ax[0,1].set_title('Hidden state')\n",
    "ax[0,1].plot(customlstm_output[0]['h_n'][0])\n",
    "\n",
    "ax[1,1].set_title('Output gate')\n",
    "ax[1,1].plot(customlstm_output[0]['o'][0])\n",
    "\n",
    "ax[2,0].set_title('Forget gate')\n",
    "ax[2,0].plot(customlstm_output[0]['f'][0])\n",
    "\n",
    "ax[2,1].set_title('Input gate')\n",
    "ax[2,1].plot(customlstm_output[0]['i'][0])\n",
    "\n",
    "ax[3,0].set_title('Cell input activation')\n",
    "ax[3,0].plot(customlstm_output[0]['g'][0])\n",
    "\n",
    "f.delaxes(ax[3,1])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots show some interesting characteristics: e.g., the cell states start to behave differently around step 210, and the gates show noticeable activity also around steps 25 and 220 which nicely coincides with high-precipitation events.\n",
    "\n",
    "That's it for this tutorial. The verbosity of `CustomLSTM`'s output gives you lots of options, and we'll leave it to your imagination as to how you want to analyze the LSTM states and activations. For instance, search for states (or combinations thereof) that correspond to physically meaningful variables, or analyze patterns in the gates' activations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
